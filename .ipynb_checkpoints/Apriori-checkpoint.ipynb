{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013c3314",
   "metadata": {},
   "source": [
    "# Apriori algorithm \n",
    "#### Apriori algorithm refers to the algorithm which is used to calculate the association rules between objects. It means how two or more objects are related to one another. In other words, we can say that the apriori algorithm is an association rule leaning that analyzes that people who bought product A also bought product B.\n",
    "\n",
    "#### The primary objective of the apriori algorithm is to create the association rule between different objects. The association rule describes how two or more objects are related to one another. Apriori algorithm is also called frequent pattern mining. \n",
    "\n",
    "## Support\n",
    "#### Support refers to the default popularity of any product. You find the support as a quotient of the division of the number of transactions comprising that product by the total number of transactions. \n",
    "\n",
    "## Confidence\n",
    "#### Confidence refers to the possibility that the customers bought both biscuits and chocolates together. So, you need to divide the number of transactions that comprise both biscuits and chocolates by the total number of transactions to get the confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97d2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d57436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_and_prepare_data(filename=\"BestBuy.csv\",colname = \"Transaction\"):\n",
    "    \"\"\"\n",
    "    Reading the csv file to get the transactions/items. Once all the transactions are read, \n",
    "    this functions finds the unique values of the entire transaction and assigns each unique item\n",
    "    to a unique value such as 0,1,2 and so on. All the transactions are converted to a list of numbers.\n",
    "    By default the file is BestBuy.csv\n",
    "    \"\"\"\n",
    "\n",
    "    read_df = pd.read_csv(filename)\n",
    "    print(read_df.columns)\n",
    "    lst=[]\n",
    "    for i in read_df[colname]:\n",
    "        lst += [i.split(',')]\n",
    "    unique=[]\n",
    "    list1=[]\n",
    "    for a in lst:\n",
    "        l1=[]\n",
    "        for b in a:\n",
    "            b= b.lstrip().rstrip()\n",
    "            l1+=[b]\n",
    "            if b not in unique:\n",
    "                unique+=[b]\n",
    "        l1.sort()\n",
    "        list1+=[l1]\n",
    "        unique.sort()\n",
    "        list2=[]\n",
    "    global dict1, key_list,val_list, X\n",
    "    dict1 = { unique[i] : i for i in range(0, len(unique) ) }\n",
    "    key_list = list(dict1.keys())\n",
    "    val_list = list(dict1.values())\n",
    "\n",
    "    for a in list1:\n",
    "        l1 = []\n",
    "        for b in a:\n",
    "            l1 += [dict1[b]]\n",
    "        list2 += [l1]\n",
    "    return np.array(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6669d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers_to_names(ck):\n",
    "    \"\"\"\n",
    "    In the read_file_and_prepare_data function we assigned each unique item to a unique number.\n",
    "    This fuction is used to revert the numbers back to their names (into understandable form instead\n",
    "    of numbers) while printing it back to the user.\n",
    "    \"\"\"\n",
    "    list_ = [list(x) for x in ck]\n",
    "    len1 = (len(list_))\n",
    "    list_form=[]\n",
    "    for i in range(0,len1):\n",
    "        if len(list_[i]) >= 1:\n",
    "            list_form1 = list_[i]\n",
    "            form=[]\n",
    "            for innerlist in list_form1:\n",
    "                a=[]\n",
    "                for i in innerlist:\n",
    "                    position = val_list.index(i)\n",
    "                    a += [key_list[position]]\n",
    "                form += [a]\n",
    "            list_form +=form\n",
    "    return list_form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981f672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1_itemset(X):\n",
    "    \"\"\"\n",
    "    create the 1-item candidate,\n",
    "    it's basically creating a frozenset for each unique item\n",
    "    and storing them in a list\n",
    "    \"\"\"\n",
    "    c1 = []\n",
    "    for transaction in X:\n",
    "        for t in transaction:\n",
    "            t = frozenset([t])\n",
    "            if t not in c1:\n",
    "                c1.append(t)\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4c930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_itemset(freq_item, k):\n",
    "    \"\"\"create the list of k-item(2,3,4...)items\"\"\"\n",
    "    ck = []\n",
    "    \n",
    "    # for generating candidate of size two (2-itemset)\n",
    "    if k == 0:\n",
    "        for f1, f2 in combinations(freq_item, 2):\n",
    "            item = f1 | f2 # union of two sets\n",
    "            ck.append(item)\n",
    "    else:    \n",
    "        for f1, f2 in combinations(freq_item, 2):       \n",
    "            # if the two (k+1)-item sets has\n",
    "            # k common elements then they will be\n",
    "            # unioned to be the (k+2)-item candidate\n",
    "            intersection = f1 & f2\n",
    "            if len(intersection) == k:\n",
    "                item = f1 | f2\n",
    "                if item not in ck:\n",
    "                    ck.append(item)\n",
    "    return ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64dbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_item(X, ck, min_support):\n",
    "    \"\"\"\n",
    "    filters the candidate with the specified\n",
    "    minimum support\n",
    "    \"\"\"\n",
    "    # loop through the transaction and compute\n",
    "    # the count for each candidate (item)\n",
    "    item_count = {}\n",
    "    for transaction in X:\n",
    "        for item in ck:\n",
    "            if item.issubset(transaction):\n",
    "                if item not in item_count: \n",
    "                    item_count[item] = 1\n",
    "                else: \n",
    "                    item_count[item] += 1    \n",
    "    \n",
    "    n_row = X.shape[0]\n",
    "    freq_item = []\n",
    "    item_support = {}\n",
    "    \n",
    "    # if the support of an item is greater than the \n",
    "    # min_support, then it is considered as frequent\n",
    "    for item in item_count:\n",
    "        support = item_count[item] / n_row\n",
    "        if support >= min_support:\n",
    "            freq_item.append(item)\n",
    "        \n",
    "        item_support[item] = support\n",
    "        \n",
    "    return freq_item, item_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7332a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(X, min_support=0.5):\n",
    "    \"\"\"\n",
    "    pass in the transaction data and the minimum support \n",
    "    threshold to obtain the frequent itemset. Also\n",
    "    store the support for each itemset, they will\n",
    "    be used in the rule generation step\n",
    "    \"\"\"\n",
    "\n",
    "    # the candidate sets for the 1-item is different,\n",
    "    # create them independently from others\n",
    "    c1 = create_1_itemset(X)\n",
    "    freq_item, item_support_dict = create_freq_item(X, c1, min_support)\n",
    "    freq_items = [freq_item]\n",
    "    freq=[]\n",
    "    k = 0\n",
    "    while len(freq_items[k]) > 0:\n",
    "        freq_item = freq_items[k]\n",
    "        ck = create_k_itemset(freq_item, k)       \n",
    "        freq_item, item_support = create_freq_item(X, ck, min_support)\n",
    "        freq_items.append(freq_item)\n",
    "        item_support_dict.update(item_support)\n",
    "        k += 1\n",
    "    freq_print = convert_numbers_to_names(freq_items)\n",
    "    return freq_print,freq_items, item_support_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecfe119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rules(freq_items, item_support_dict, min_confidence):\n",
    "    \"\"\"\n",
    "    create the association rules, the rules will be a list.\n",
    "    each element is a tuple of size 4, containing rules'\n",
    "    left hand side, right hand side, confidence and lift\n",
    "    \"\"\"\n",
    "    association_rules = []\n",
    "\n",
    "    # for the list that stores the frequent items, loop through\n",
    "    # the second element to the one before the last to generate the rules\n",
    "    # because the last one will be an empty list. It's the stopping criteria\n",
    "    # for the frequent itemset generating process and the first one are all\n",
    "    # single element frequent itemset, which can't perform the set\n",
    "    # operation X -> Y - X\n",
    "    for idx, freq_item in enumerate(freq_items[1:(len(freq_items) - 1)]):\n",
    "        for freq_set in freq_item:\n",
    "            \n",
    "            # start with creating rules for single item on\n",
    "            # the right hand side\n",
    "            subsets = [frozenset([item]) for item in freq_set]\n",
    "            rules, right_hand_side = compute_conf(freq_items, item_support_dict, \n",
    "                                                  freq_set, subsets, min_confidence)\n",
    "            association_rules.extend(rules)\n",
    "            \n",
    "            # starting from 3-itemset, loop through each length item\n",
    "            # to create the rules, as for the while loop condition,\n",
    "            # e.g. suppose you start with a 3-itemset {2, 3, 5} then the \n",
    "            # while loop condition will stop when the right hand side's\n",
    "            # item is of length 2, e.g. [ {2, 3}, {3, 5} ], since this\n",
    "            # will be merged into 3 itemset, making the left hand side\n",
    "            # null when computing the confidence\n",
    "            if idx != 0:\n",
    "                k = 0\n",
    "                while len(right_hand_side[0]) < len(freq_set) - 1:\n",
    "                    ck = create_k_itemset(right_hand_side, k = k)\n",
    "                    rules, right_hand_side = compute_conf(freq_items, item_support_dict,\n",
    "                                                          freq_set, ck, min_confidence)\n",
    "                    association_rules.extend(rules)\n",
    "                    k += 1   \n",
    "    rules_df = pd.DataFrame(association_rules,columns=['First_item',\"buys\",\"Second_item\",\"confidence_value\"])\n",
    "    list_first_item = [list(rules_df['First_item'])]\n",
    "    list_second_item = [list(rules_df['Second_item'])]\n",
    "    rules_df[\"First_item\"] = convert_numbers_to_names(list_first_item)\n",
    "    rules_df[\"Second_item\"] = convert_numbers_to_names(list_second_item)\n",
    "    return rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bed2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conf(freq_items, item_support_dict, freq_set, subsets, min_confidence=0.5):\n",
    "    \"\"\"\n",
    "    create the rules and returns the rules info and the rules's\n",
    "    right hand side (used for generating the next round of rules) \n",
    "    if it surpasses the minimum confidence threshold\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    right_hand_side = []\n",
    "    \n",
    "    for rhs in subsets:\n",
    "        # create the left hand side of the rule\n",
    "        # and add the rules if it's greater than\n",
    "        # the confidence threshold\n",
    "        lhs = freq_set - rhs\n",
    "        conf = item_support_dict[freq_set] / item_support_dict[lhs]\n",
    "        if conf >= min_confidence:\n",
    "            rules_info = lhs,\"->\", rhs, conf\n",
    "            rules.append(rules_info)\n",
    "            right_hand_side.append(rhs)\n",
    "            \n",
    "    return rules, right_hand_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a1832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "    In this function, all the required inputs are provided by the user \n",
    "    such as the filename, support value and confidence value.\n",
    "    These inputs are provided in the function call\n",
    "    \"\"\"\n",
    "    file = input(\"Enter the File Name(CSV) [if in different directory please provide the address with the file]\\n\")\n",
    "    if \".xlsx\" in file:\n",
    "        read_file = pd.read_excel(file)\n",
    "        read_file.to_csv (file, index = None, header=True)\n",
    "    X = read_file_and_prepare_data(file)\n",
    "    while True:\n",
    "        try:\n",
    "            min_support = float(input(\"Enter the SUPPORT value in the range of (0.0 - 1.0) : \"))\n",
    "            if min_support >=0.0 and min_support <=1.0:\n",
    "                break\n",
    "        except:\n",
    "            min_support = 0.5\n",
    "    while True:\n",
    "        try:\n",
    "            min_confidence = float(input(\"Enter the CONFIDENCE value in the range of (0.0 - 1.0) : \"))\n",
    "            if min_confidence >= 0.0 and min_confidence <= 1.0:\n",
    "                break\n",
    "        except:\n",
    "            min_confidence = 0.5\n",
    "    freq_print,freq_items, item_support_dict = apriori(X, min_support)\n",
    "    print(\"-\"*120)\n",
    "    print(\"The Minimum support value is : \",min_support)\n",
    "    print(\"The Minimum Confidence value is : \",min_confidence)\n",
    "    print(\"-\"*120)\n",
    "    print(\"The Frequent itemset which is above or equal to the given support value: \\n\")\n",
    "    print(freq_print)\n",
    "    rules_df = create_rules(freq_items, item_support_dict, min_confidence)\n",
    "    print(\"-\"*120)\n",
    "    print(\"The rules with their confidence values are : \\n\")\n",
    "    print(rules_df)\n",
    "    rules_df.to_csv(\"output.csv\")\n",
    "    print(\"-\"*120)\n",
    "    print(\"The rules with their confidence value are available in output.csv file\")\n",
    "    print(\"-\"*120)\n",
    "    print(\"-\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3448a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the File Name(CSV) [if in different directory please provide the address with the file]\n",
      "files/BestBuy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3e6d5c49a600>:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(list2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Transaction ID ', 'Transaction'], dtype='object')\n",
      "Enter the SUPPORT value in the range of (0.0 - 1.0) : 40\n",
      "Enter the SUPPORT value in the range of (0.0 - 1.0) : \n",
      "Enter the SUPPORT value in the range of (0.0 - 1.0) : a\n",
      "Enter the SUPPORT value in the range of (0.0 - 1.0) : b\n",
      "Enter the SUPPORT value in the range of (0.0 - 1.0) : 0.4\n",
      "Enter the CONFIDENCE value in the range of (0.0 - 1.0) : a\n",
      "Enter the CONFIDENCE value in the range of (0.0 - 1.0) : 50\n",
      "Enter the CONFIDENCE value in the range of (0.0 - 1.0) : 0.5\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "The Minimum support value is :  0.4\n",
      "The Minimum Confidence value is :  0.5\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "The Frequent itemset which is above or equal to the given support value: \n",
      "\n",
      "[['Anti-Virus'], ['Flash Drive'], ['Microsoft Office'], ['Printer'], ['Speakers'], ['Lab Top'], ['Lab Top Case'], ['External Hard-Drive'], ['Digital Camera'], ['Anti-Virus', 'Flash Drive'], ['Anti-Virus', 'Microsoft Office'], ['Anti-Virus', 'Speakers'], ['Flash Drive', 'Microsoft Office'], ['Printer', 'Flash Drive'], ['Printer', 'Microsoft Office'], ['Anti-Virus', 'Lab Top'], ['Anti-Virus', 'Lab Top Case'], ['Flash Drive', 'Lab Top Case'], ['Lab Top', 'Lab Top Case'], ['Anti-Virus', 'External Hard-Drive'], ['External Hard-Drive', 'Lab Top Case'], ['Speakers', 'Lab Top Case'], ['Anti-Virus', 'Flash Drive', 'Microsoft Office'], ['Printer', 'Flash Drive', 'Microsoft Office'], ['Anti-Virus', 'Flash Drive', 'Lab Top Case'], ['Anti-Virus', 'Lab Top', 'Lab Top Case'], ['Anti-Virus', 'External Hard-Drive', 'Lab Top Case'], ['Anti-Virus', 'Speakers', 'Lab Top Case']]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "The rules with their confidence values are : \n",
      "\n",
      "                    First_item buys                 Second_item  \\\n",
      "0                [Flash Drive]   ->                [Anti-Virus]   \n",
      "1                 [Anti-Virus]   ->               [Flash Drive]   \n",
      "2           [Microsoft Office]   ->                [Anti-Virus]   \n",
      "3                 [Anti-Virus]   ->          [Microsoft Office]   \n",
      "4                   [Speakers]   ->                [Anti-Virus]   \n",
      "..                         ...  ...                         ...   \n",
      "57  [Anti-Virus, Lab Top Case]   ->                  [Speakers]   \n",
      "58      [Anti-Virus, Speakers]   ->              [Lab Top Case]   \n",
      "59              [Lab Top Case]   ->      [Anti-Virus, Speakers]   \n",
      "60                  [Speakers]   ->  [Anti-Virus, Lab Top Case]   \n",
      "61                [Anti-Virus]   ->    [Speakers, Lab Top Case]   \n",
      "\n",
      "    confidence_value  \n",
      "0           0.769231  \n",
      "1           0.714286  \n",
      "2           0.727273  \n",
      "3           0.571429  \n",
      "4           0.818182  \n",
      "..               ...  \n",
      "57          0.666667  \n",
      "58          0.888889  \n",
      "59          0.571429  \n",
      "60          0.727273  \n",
      "61          0.571429  \n",
      "\n",
      "[62 rows x 4 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "The rules with their confidence value are available in output.csv file\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae448c",
   "metadata": {},
   "source": [
    "# The csv file needs to be formatted before running the apriori algorithm\n",
    "### The csv file looks\n",
    "![excel](excel.png)\n",
    "### This file is formatted as shown in the picture below\n",
    "![formatted](formatted.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e1854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction ID                Transaction\n",
      "0         Trans1     ink, pen, cheese, bag \n",
      "1         Trans2  milk, pen, juice, cheese \n",
      "2         Trans3               milk, juice \n",
      "3         Trans4       juice, milk, cheese \n",
      "4         Trans5     ink, pen, cheese, bag \n",
      "5         Trans6  milk, pen, juice, cheese \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def file_format(filename):\n",
    "    \"\"\"This Function is used to reformat the file\"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    list_values = df.values.tolist()\n",
    "    split=[]\n",
    "    for i in list_values:\n",
    "        for j in i:\n",
    "            split += [j.split(\" \", maxsplit =1)]\n",
    "    return_df = pd.DataFrame(split, columns=['Transaction ID', 'Transaction'])\n",
    "    return_df.to_csv(filename,index=False)\n",
    "    print(return_df)\n",
    "file_format(\"files/custom_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d3d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
